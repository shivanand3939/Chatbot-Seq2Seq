{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJAWnBFlkE2w"
   },
   "source": [
    "# LSTM Bot\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this project, you will build a chatbot that can converse with you at the command line. The chatbot will use a Sequence to Sequence text generation architecture with an LSTM as it's memory unit. You will also learn to use pretrained word embeddings to improve the performance of the model. At the conclusion of the project, you will be able to show your chatbot to potential employers.\n",
    "\n",
    "Additionally, you have the option to use pretrained word embeddings in your model. We have loaded Brown Embeddings from Gensim in the starter code below. You can compare the performance of your model with pre-trained embeddings against a model without the embeddings.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "A sequence to sequence model (Seq2Seq) has two components:\n",
    "- An Encoder consisting of an embedding layer and LSTM unit.\n",
    "- A Decoder consisting of an embedding layer, LSTM unit, and linear output unit.\n",
    "\n",
    "The Seq2Seq model works by accepting an input into the Encoder, passing the hidden state from the Encoder to the Decoder, which the Decoder uses to output a series of token predictions.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- Pytorch\n",
    "- Numpy\n",
    "- Pandas\n",
    "- NLTK\n",
    "- Gzip\n",
    "- Gensim\n",
    "\n",
    "\n",
    "Please choose a dataset from the Torchtext website. We recommend looking at the Squad dataset first. Here is a link to the website where you can view your options:\n",
    "\n",
    "- https://pytorch.org/text/stable/datasets.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /root/.local/lib/python3.7/site-packages (22.3.1)\n",
      "Requirement already satisfied: setuptools in /root/.local/lib/python3.7/site-packages (65.6.3)\n",
      "Requirement already satisfied: wheel in /root/.local/lib/python3.7/site-packages (0.38.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in /root/.local/lib/python3.7/site-packages (3.4.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.11.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /root/.local/lib/python3.7/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /root/.local/lib/python3.7/site-packages (from spacy) (4.1.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (4.43.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (20.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /root/.local/lib/python3.7/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /root/.local/lib/python3.7/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /root/.local/lib/python3.7/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.21.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /root/.local/lib/python3.7/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /root/.local/lib/python3.7/site-packages (from spacy) (8.1.6)\n",
      "Requirement already satisfied: setuptools in /root/.local/lib/python3.7/site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.23.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /root/.local/lib/python3.7/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /root/.local/lib/python3.7/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /root/.local/lib/python3.7/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /root/.local/lib/python3.7/site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /root/.local/lib/python3.7/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /root/.local/lib/python3.7/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /root/.local/lib/python3.7/site-packages (from spacy) (1.10.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.7)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /root/.local/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /root/.local/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /root/.local/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy) (1.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /root/.local/lib/python3.7/site-packages (from en-core-web-sm==3.4.1) (3.4.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /root/.local/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /root/.local/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (20.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /root/.local/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.4)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /root/.local/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /root/.local/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /root/.local/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /root/.local/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.23.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /root/.local/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /root/.local/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /root/.local/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.21.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /root/.local/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /root/.local/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /root/.local/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.11.1)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /root/.local/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.1.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.43.0)\n",
      "Requirement already satisfied: setuptools in /root/.local/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (65.6.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2019.11.28)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.25.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.9)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /root/.local/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /root/.local/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /root/.local/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchtext==0.10.0 in /root/.local/lib/python3.7/site-packages (0.10.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchtext==0.10.0) (2.23.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchtext==0.10.0) (1.21.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtext==0.10.0) (4.43.0)\n",
      "Requirement already satisfied: torch==1.9.0 in /root/.local/lib/python3.7/site-packages (from torchtext==0.10.0) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions in /root/.local/lib/python3.7/site-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.10.0) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.10.0) (1.25.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.10.0) (2019.11.28)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U pip setuptools wheel\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install -U torchtext==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch \n",
    "# !pip install typing-extensions --upgrade\n",
    "# !pip install -U torchtext\n",
    "# !pip install spacy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.utils import download_from_url\n",
    "import json, os\n",
    "\n",
    "URLS = {\n",
    "    'SQuAD1':\n",
    "        ['https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json',\n",
    "         'https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json'],\n",
    "    'SQuAD2':\n",
    "        ['https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json',\n",
    "         'https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json']\n",
    "}\n",
    "\n",
    "\n",
    "def _create_data_from_json(data_path):\n",
    "    with open(data_path) as json_file:\n",
    "        raw_json_data = json.load(json_file)['data']\n",
    "        for layer1 in raw_json_data:\n",
    "            for layer2 in layer1['paragraphs']:\n",
    "                for layer3 in layer2['qas']:\n",
    "                    processed = {'context': layer2['context'], 'question': layer3['question'],\n",
    "                                 'answers': [item['text'] for item in layer3['answers']],\n",
    "                                 'answer_start': [item['answer_start'] for item in layer3['answers']]}\n",
    "                    if len(processed['answers']) == 0:\n",
    "                        processed['answers'] = [\"\"]\n",
    "                        processed['answer_start'] = [-1]\n",
    "                    yield processed\n",
    "\n",
    "\n",
    "class RawQuestionAnswerDataset(torch.utils.data.IterableDataset):\n",
    "    \"\"\"Defines an abstraction for raw question answer iterable datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, iterator):\n",
    "        \"\"\"Initiate text-classification dataset.\n",
    "        \"\"\"\n",
    "        super(RawQuestionAnswerDataset, self).__init__()\n",
    "        self._iterator = iterator\n",
    "        self.has_setup = False\n",
    "        self.start = 0\n",
    "        self.num_lines = None\n",
    "\n",
    "    def setup_iter(self, start=0, num_lines=None):\n",
    "        self.start = start\n",
    "        self.num_lines = num_lines\n",
    "        self.has_setup = True\n",
    "\n",
    "    def __iter__(self):\n",
    "        if not self.has_setup:\n",
    "            self.setup_iter()\n",
    "\n",
    "        for i, item in enumerate(self._iterator):\n",
    "            if i >= self.start:\n",
    "                yield item\n",
    "            if self.num_lines is not None and i == (self.start + self.num_lines):\n",
    "                break\n",
    "\n",
    "\n",
    "def _setup_datasets(dataset_name, root='./data'):\n",
    "    extracted_files = []\n",
    "    select_to_index = {'train': 0, 'dev': 1}\n",
    "    extracted_files = [download_from_url(URLS[dataset_name][select_to_index[key]],\n",
    "                                         root=root) for key in select_to_index.keys()]\n",
    "    train_iter = _create_data_from_json(extracted_files[0])\n",
    "    dev_iter = _create_data_from_json(extracted_files[1])\n",
    "    return (RawQuestionAnswerDataset(train_iter),\n",
    "            RawQuestionAnswerDataset(dev_iter))\n",
    "\n",
    "\n",
    "def SQuAD1(*args, **kwargs):\n",
    "    \"\"\" Defines SQuAD1 datasets.\n",
    "    Examples:\n",
    "        >>> train, dev = torchtext.experimental.datasets.raw.SQuAD1()\n",
    "    \"\"\"\n",
    "\n",
    "    return _setup_datasets(*((\"SQuAD1\",) + args), **kwargs)\n",
    "\n",
    "\n",
    "def SQuAD2(*args, **kwargs):\n",
    "    \"\"\" Defines SQuAD2 datasets.\n",
    "    Examples:\n",
    "        >>> train, dev = torchtext.experimental.datasets.raw.SQuAD2()\n",
    "    \"\"\"\n",
    "\n",
    "    return _setup_datasets(*((\"SQuAD2\",) + args), **kwargs)\n",
    "\n",
    "\n",
    "DATASETS = {\n",
    "    'SQuAD1': SQuAD1,\n",
    "    'SQuAD2': SQuAD2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_json('./data/train-v1.1.json') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'title': 'University_of_Notre_Dame', 'paragra...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'title': 'Beyoncé', 'paragraphs': [{'context'...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'title': 'Montana', 'paragraphs': [{'context'...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'title': 'Genocide', 'paragraphs': [{'context...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'title': 'Antibiotics', 'paragraphs': [{'cont...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  version\n",
       "0  {'title': 'University_of_Notre_Dame', 'paragra...      1.1\n",
       "1  {'title': 'Beyoncé', 'paragraphs': [{'context'...      1.1\n",
       "2  {'title': 'Montana', 'paragraphs': [{'context'...      1.1\n",
       "3  {'title': 'Genocide', 'paragraphs': [{'context...      1.1\n",
       "4  {'title': 'Antibiotics', 'paragraphs': [{'cont...      1.1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_vocab_from_iterator =train['data'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "ans = []\n",
    "ques = []\n",
    "\n",
    "\n",
    "for value in build_vocab_from_iterator:\n",
    "    for each in value['paragraphs'][0]['qas']:\n",
    "        ans.append(each['answers'][0]['text'])\n",
    "        ques.append(each['question'])\n",
    "        ids.append(each['id'])\n",
    "        if len(each['answers']) > 1:\n",
    "            print(each)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>ques</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ids  \\\n",
       "0  5733be284776f41900661182   \n",
       "1  5733be284776f4190066117f   \n",
       "2  5733be284776f41900661180   \n",
       "3  5733be284776f41900661181   \n",
       "4  5733be284776f4190066117e   \n",
       "\n",
       "                                                ques  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                       ans  \n",
       "0               Saint Bernadette Soubirous  \n",
       "1                a copper statue of Christ  \n",
       "2                        the Main Building  \n",
       "3  a Marian place of prayer and reflection  \n",
       "4       a golden statue of the Virgin Mary  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = pd.DataFrame([ [i,j,k] for i,j,k in zip(ids, ques, ans)], columns = ['ids', 'ques', 'ans'])\n",
    "train_dataset.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate appropriate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import nltk, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import torch\n",
    "from nltk.corpus import brown\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "import spacy\n",
    "\n",
    "# Output, save, and load brown embeddings\n",
    "model = gensim.models.Word2Vec(brown.sents())\n",
    "model.save('brown.embedding')\n",
    "\n",
    "w2v = gensim.models.Word2Vec.load('brown.embedding')\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    " \n",
    "def loadDF(path):\n",
    "    '''\n",
    "  \n",
    "    You will use this function to load the dataset into a Pandas Dataframe for processing.\n",
    "\n",
    "    '''\n",
    "    df = pd.read_json(path)\n",
    "    #train = pd.read_json('./data/train-v1.1.json') \n",
    "    build_vocab_from_iterator =df['data'].values \n",
    "    ids = []\n",
    "    ans = []\n",
    "    ques = []\n",
    "\n",
    "\n",
    "    for value in build_vocab_from_iterator:\n",
    "        for each in value['paragraphs'][0]['qas']:\n",
    "            ans.append(each['answers'][0]['text'])\n",
    "            ques.append(each['question'])\n",
    "            ids.append(each['id'])\n",
    "    train_dataset = pd.DataFrame([ [i,j,k] for i,j,k in zip(ids, ques, ans)], columns = ['ids', 'Ques', 'Ans'])\n",
    "\n",
    "    return train_dataset\n",
    "\n",
    "\n",
    "def prepare_text(sentence):\n",
    "    \n",
    "    '''\n",
    "\n",
    "    Our text needs to be cleaned with a tokenizer. This function will perform that task.\n",
    "    https://www.nltk.org/api/nltk.tokenize.html\n",
    "\n",
    "    '''\n",
    "    \n",
    "    return [tok.text for tok in spacy_en.tokenizer(sentence)]   \n",
    "\n",
    "\n",
    "\n",
    "def train_test_split(SRC=None, TRG=None):\n",
    "    \n",
    "    '''\n",
    "    Input: SRC, our list of questions from the dataset\n",
    "            TRG, our list of responses from the dataset\n",
    "\n",
    "    Output: Training and test datasets for SRC & TRG\n",
    "\n",
    "    '''\n",
    "    bos = [\"<BOS> \"]\n",
    "    \n",
    "    eos = [\" <EOS>\"]\n",
    "    \n",
    "    train = loadDF('./data/train-v1.1.json')\n",
    "    SRC_train_dataset = [bos + prepare_text(each) + eos for each in train.ques.values]\n",
    "    TRG_train_dataset = [bos + prepare_text(each) + eos for each in train.ans.values]\n",
    "    \n",
    "    test = loadDF('./data/dev-v1.1.json')\n",
    "    SRC_test_dataset = [bos + prepare_text(each) + eos for each in test.ques.values]\n",
    "    TRG_test_dataset = [bos + prepare_text(each) + eos for each in test.ans.values]\n",
    "    \n",
    "    #SRC_train_dataset = [ [bos] + sent + eos for sent in SRC_train_dataset]\n",
    "    #TRG_train_dataset = [ bos + sent + eos for sent in TRG_train_dataset]\n",
    "    \n",
    "    #SRC_test_dataset = [ bos + sent + eos for sent in SRC_test_dataset]\n",
    "    #TRG_test_dataset = [ bos + sent + eos for sent in TRG_test_dataset]\n",
    "    \n",
    "    return SRC_train_dataset, SRC_test_dataset, TRG_train_dataset, TRG_test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00207365,  0.02666673, -0.00453171, -0.05273971,  0.01784584,\n",
       "       -0.06991713,  0.00554869,  0.02328627,  0.00014236, -0.0170673 ,\n",
       "        0.02023535, -0.03714994, -0.02138056,  0.00796599,  0.04087447,\n",
       "       -0.01110171,  0.0421456 , -0.02751041, -0.00795583, -0.03105834,\n",
       "        0.04115778,  0.0389748 ,  0.02551365,  0.0205302 , -0.00317072,\n",
       "       -0.02616424, -0.02052782,  0.00032259,  0.01723288, -0.02231467,\n",
       "        0.07344069, -0.03654412,  0.01949139, -0.02212733,  0.00249744,\n",
       "       -0.01764404, -0.00681961,  0.06774941,  0.02764932, -0.04710691,\n",
       "        0.02022763, -0.03852994, -0.00343246,  0.00658672,  0.01837641,\n",
       "       -0.0225295 , -0.04328559,  0.03185142,  0.01849885,  0.032887  ,\n",
       "       -0.02174715, -0.00568397,  0.033268  , -0.01307951, -0.00217068,\n",
       "        0.03895813,  0.03854025,  0.04190052,  0.00080813,  0.02923417,\n",
       "       -0.00251668,  0.00868551, -0.00021046,  0.02190729, -0.03805066,\n",
       "        0.0378219 ,  0.01983622,  0.0223449 , -0.03132726,  0.07111472,\n",
       "       -0.03132326, -0.00716446,  0.07485037, -0.01255209,  0.0573024 ,\n",
       "       -0.02534898, -0.01400166,  0.02744011, -0.00246463, -0.01820287,\n",
       "        0.00370596, -0.01495702, -0.00928   ,  0.04194199,  0.00312824,\n",
       "        0.04120321,  0.01129575,  0.02167748,  0.05168802, -0.03479802,\n",
       "       -0.00496362, -0.003727  ,  0.01269521,  0.00527347,  0.02863071,\n",
       "        0.03096775,  0.01994858, -0.02204115, -0.04114479, -0.00715766],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv['Hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SRC_train_dataset, SRC_test_dataset, TRG_train_dataset, TRG_test_dataset = train_test_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRG_test_dataset[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset to be used by the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Generate the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = loadDF('./data/train-v1.1.json')\n",
    "train.iloc[:100000, 1:3].to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = loadDF('./data/dev-v1.1.json')\n",
    "train.iloc[:10000, 1:3].to_csv('test.csv')\n",
    "\n",
    "train.iloc[10000:20000, 1:3].to_csv('dev.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Generate the fields / iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, spacy, re\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "#from tokenizers import Tokenizer\n",
    "\n",
    "def tokenise(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "\n",
    "def get_fields():\n",
    "    src_q = Field(tokenize = tokenise, init_token='<BOS>', eos_token='<EOS>', lower=True)\n",
    "    tar_q = Field(tokenize = tokenise, init_token='<BOS>', eos_token='<EOS>', lower=True)\n",
    "\n",
    "    src_orig = Field(init_token='<BOS>', eos_token='<EOS>', lower=True)\n",
    "    tar_orig = Field(init_token='<BOS>', eos_token='<EOS>', lower=True)\n",
    "    return src_q, tar_q, src_orig, tar_orig\n",
    "\n",
    "\n",
    "src_q, tar_q, src_orig, tar_orig = get_fields()\n",
    "\n",
    "fields = { 'Ques': ('src', src_q), 'Ans': ('trg', tar_q ) }\n",
    "orig_fields = { 'Ques': ('src_orig', src_orig), 'Ans': ('trg_orig', tar_orig ) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Tokenised Field Data\n",
    "def get_data(train='train.csv', dev='dev.csv', test='test.csv'):\n",
    "    train, valid, test = TabularDataset.splits(\n",
    "                path = '',\n",
    "                train = train,\n",
    "                validation = dev,\n",
    "                test = test,\n",
    "                format = 'csv',\n",
    "                fields = fields)\n",
    "\n",
    "    return train, valid, test\n",
    "\n",
    "\n",
    "#Get Original Data\n",
    "def get_original_data(train='train.csv', dev='dev.csv', test='test.csv'):\n",
    "    train, valid, test = TabularDataset.splits(\n",
    "                path = '',\n",
    "                train = train,\n",
    "                validation = dev,\n",
    "                test = test,\n",
    "                format = 'csv',\n",
    "                fields = orig_fields)\n",
    "\n",
    "    return train, valid, test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get Iterator Bucket data\n",
    "\n",
    "def get_iterators(train='train.csv', dev='dev.csv', test='test.csv', batch_size=32):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    src_q.build_vocab(train, min_freq = 2)\n",
    "    tar_q.build_vocab(train, min_freq = 2)\n",
    "    train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "        (train_data, valid_data, test_data),\n",
    "        batch_size = batch_size,\n",
    "        sort_key=lambda x: len(x.src),\n",
    "        sort_within_batch=False,\n",
    "        device = device)\n",
    "    return train_iterator, valid_iterator, test_iterator, src_q, tar_q\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.10.0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchtext\n",
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# from torchtext.legacy.datasets import Multi30k\n",
    "# from torchtext.legacy.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oQLTP2Wmi1eB"
   },
   "outputs": [],
   "source": [
    "# class Encoder(nn.Module):\n",
    "    \n",
    "#     def __init__(self, input_size, hidden_size):\n",
    "        \n",
    "#         super(Encoder, self).__init__()\n",
    "        \n",
    "#         # self.embedding provides a vector representation of the inputs to our model\n",
    "#         self.hid_dim = hid_dim\n",
    "#         self.n_layers = 1\n",
    "        \n",
    "#         # self.lstm, accepts the vectorized input and passes a hidden state\n",
    "        \n",
    "    \n",
    "#     def forward(self, i):\n",
    "        \n",
    "#         '''\n",
    "#         Inputs: i, the src vector\n",
    "#         Outputs: o, the encoder outputs\n",
    "#                 h, the hidden state\n",
    "#                 c, the cell state\n",
    "#         '''\n",
    "        \n",
    "#         return o, h, c\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return hidden, cell\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Decoder(nn.Module):\n",
    "      \n",
    "#     def __init__(self, hidden_size, output_size):\n",
    "        \n",
    "#         super(Decoder, self).__init__()\n",
    "        \n",
    "#         # self.embedding provides a vector representation of the target to our model\n",
    "        \n",
    "#         # self.lstm, accepts the embeddings and outputs a hidden state\n",
    "\n",
    "#         # self.ouput, predicts on the hidden state via a linear output layer     \n",
    "        \n",
    "#     def forward(self, i, h):\n",
    "        \n",
    "#         '''\n",
    "#         Inputs: i, the target vector\n",
    "#         Outputs: o, the prediction\n",
    "#                 h, the hidden state\n",
    "#         '''\n",
    "        \n",
    "#         return o, h\n",
    "        \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        \n",
    "        #input = [batch size]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "                \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        \n",
    "        #output = [seq len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "        \n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden, cell        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Seq2Seq(nn.Module):\n",
    "    \n",
    "#     def __init__(self, encoder_input_size, encoder_hidden_size, decoder_hidden_size, decoder_output_size):\n",
    "        \n",
    "#         super(Seq2Seq, self).__init__()\n",
    "        \n",
    "    \n",
    "    \n",
    "#     def forward(self, src, trg, teacher_forcing_ratio = 0.5):      \n",
    "        \n",
    "#         return o\n",
    "\n",
    "    \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        #first input to the decoder is the  tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (tw) vocabulary: 2054\n",
      "Unique tokens in target (en) vocabulary: 1245\n"
     ]
    }
   ],
   "source": [
    "SEED = 1234\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 10\n",
    "CURRENT_EPOCH = 0\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "train_data, valid_data, test_data = get_data()\n",
    "train_iterator, valid_iterator, _, src_tw, trg_en = get_iterators(train_data, valid_data, test_data, BATCH_SIZE)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Unique tokens in source (tw) vocabulary: {len(src_tw.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(trg_en.vocab)}\")\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight\n",
      "weight_ih_l0\n",
      "weight_hh_l0\n",
      "bias_ih_l0\n",
      "bias_hh_l0\n",
      "weight_ih_l1\n",
      "weight_hh_l1\n",
      "bias_ih_l1\n",
      "bias_hh_l1\n",
      "embedding.weight\n",
      "rnn.weight_ih_l0\n",
      "rnn.weight_hh_l0\n",
      "rnn.bias_ih_l0\n",
      "rnn.bias_hh_l0\n",
      "rnn.weight_ih_l1\n",
      "rnn.weight_hh_l1\n",
      "rnn.bias_ih_l1\n",
      "rnn.bias_hh_l1\n",
      "weight\n",
      "weight_ih_l0\n",
      "weight_hh_l0\n",
      "bias_ih_l0\n",
      "bias_hh_l0\n",
      "weight_ih_l1\n",
      "weight_hh_l1\n",
      "bias_ih_l1\n",
      "bias_hh_l1\n",
      "weight\n",
      "bias\n",
      "embedding.weight\n",
      "rnn.weight_ih_l0\n",
      "rnn.weight_hh_l0\n",
      "rnn.bias_ih_l0\n",
      "rnn.bias_hh_l0\n",
      "rnn.weight_ih_l1\n",
      "rnn.weight_hh_l1\n",
      "rnn.bias_ih_l1\n",
      "rnn.bias_hh_l1\n",
      "fc_out.weight\n",
      "fc_out.bias\n",
      "encoder.embedding.weight\n",
      "encoder.rnn.weight_ih_l0\n",
      "encoder.rnn.weight_hh_l0\n",
      "encoder.rnn.bias_ih_l0\n",
      "encoder.rnn.bias_hh_l0\n",
      "encoder.rnn.weight_ih_l1\n",
      "encoder.rnn.weight_hh_l1\n",
      "encoder.rnn.bias_ih_l1\n",
      "encoder.rnn.bias_hh_l1\n",
      "decoder.embedding.weight\n",
      "decoder.rnn.weight_ih_l0\n",
      "decoder.rnn.weight_hh_l0\n",
      "decoder.rnn.bias_ih_l0\n",
      "decoder.rnn.bias_hh_l0\n",
      "decoder.rnn.weight_ih_l1\n",
      "decoder.rnn.weight_hh_l1\n",
      "decoder.rnn.bias_ih_l1\n",
      "decoder.rnn.bias_hh_l1\n",
      "decoder.fc_out.weight\n",
      "decoder.fc_out.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(2054, 100)\n",
       "    (rnn): LSTM(100, 512, num_layers=2, dropout=0.1)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(1245, 100)\n",
       "    (rnn): LSTM(100, 512, num_layers=2, dropout=0.1)\n",
       "    (fc_out): Linear(in_features=512, out_features=1245, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "INPUT_DIM, OUTPUT_DIM = len(src_tw.vocab), len(trg_en.vocab) \n",
    "ENC_EMB_DIM = 100\n",
    "DEC_EMB_DIM = 100\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "def init_weights(module):\n",
    "    for name, param in module.named_parameters():\n",
    "        print(name)\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 7,686,025 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "PAD_IDX = trg_en.vocab.stoi[trg_en.pad_token] # ignore padding index when calculating loss\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / (len(iterator) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 10s\n",
      "\tTrain Loss: 7.118 | Train PPL: 1234.481\n",
      "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n",
      "Epoch: 02 | Time: 0m 10s\n",
      "\tTrain Loss: 7.107 | Train PPL: 1220.643\n",
      "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n",
      "Epoch: 03 | Time: 0m 10s\n",
      "\tTrain Loss: 7.095 | Train PPL: 1206.502\n",
      "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n",
      "Epoch: 04 | Time: 0m 10s\n",
      "\tTrain Loss: 7.083 | Train PPL: 1191.674\n",
      "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n",
      "Epoch: 05 | Time: 0m 10s\n",
      "\tTrain Loss: 7.069 | Train PPL: 1175.377\n",
      "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n",
      "Epoch: 06 | Time: 0m 10s\n",
      "\tTrain Loss: 7.054 | Train PPL: 1157.190\n",
      "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n",
      "Epoch: 07 | Time: 0m 10s\n",
      "\tTrain Loss: 7.037 | Train PPL: 1138.410\n",
      "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n",
      "Epoch: 08 | Time: 0m 10s\n",
      "\tTrain Loss: 7.018 | Train PPL: 1116.375\n",
      "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n",
      "Epoch: 09 | Time: 0m 10s\n",
      "\tTrain Loss: 6.994 | Train PPL: 1090.586\n",
      "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n",
      "Epoch: 10 | Time: 0m 10s\n",
      "\tTrain Loss: 6.963 | Train PPL: 1056.839\n",
      "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# from utils import translate_sentence\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_data, valid_data, test_data = get_data()\n",
    "og_train_data, og_valid_data, og_test_data = get_original_data()\n",
    "_, _, test_iterator, src_tw, trg_en = get_iterators(train_data, valid_data, test_data, BATCH_SIZE)\n",
    "PAD_IDX = trg_en.vocab.stoi[trg_en.pad_token] # ignore padding index when calculating loss\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "\n",
    "\n",
    "\n",
    "# example_idx = randrange(len(og_valid_data.examples))\n",
    "# example = valid_data.examples[example_idx]\n",
    "# og_example = og_valid_data.examples[example_idx]\n",
    "# orig_source = ' '.join(og_example.src_orig)\n",
    "# print('ORIG SOURCE: ', orig_source)\n",
    "# orig_target = ' '.join(og_example.trg_orig)\n",
    "# print('ORIG TARGET: ', orig_target)\n",
    "# preprocessed_source = ' '.join(example.src[::-1])\n",
    "# print('TOKENIZED SOURCE: ', preprocessed_source)\n",
    "# preprocessed_target = ' '.join(example.trg)\n",
    "# refs = example.trg\n",
    "# print('TOKENIZED TARGET: ', preprocessed_target)\n",
    "#\n",
    "# src_tensor = src_tw.process([example.src]).to(device)\n",
    "# trg_tensor = trg_en.process([example.trg]).to(device)\n",
    "#\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(src_tensor, trg_tensor, teacher_forcing_ratio=0)\n",
    "#\n",
    "# output_idx = outputs[1:].squeeze(1).argmax(1)\n",
    "# # itos: A list of token strings indexed by their numerical identifiers.\n",
    "# generation = [trg_en.vocab.itos[idx] for idx in output_idx]\n",
    "# predicted_translation = []\n",
    "# for word in generation:\n",
    "#     if word == '<eos>': break\n",
    "#     predicted_translation.append(word)\n",
    "# predicted_translation = ' '.join(predicted_translation)\n",
    "# print('TRANSLATION: ', ' '.join(predicted_translation))\n",
    "\n",
    "\n",
    "# write to translation files to use when calculating BLEU\n",
    "file_ref = open(\"target_translation.txt\", \"a\")  # append mode\n",
    "file_pred = open(\"predicted_translation.txt\", \"a\")  # append mode\n",
    "\n",
    "for i in range(len(test_data.examples)):\n",
    "    example = test_data.examples[i]\n",
    "    preprocessed_target = ' '.join(example.trg) + '\\n'\n",
    "    file_ref.write(preprocessed_target)\n",
    "\n",
    "    src_tensor = src_tw.process([example.src]).to(device)\n",
    "    trg_tensor = trg_en.process([example.trg]).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(src_tensor, trg_tensor, teacher_forcing_ratio=0)\n",
    "\n",
    "    output_idx = outputs[1:].squeeze(1).argmax(1)\n",
    "    \n",
    "    # itos: A list of token strings indexed by their numerical identifiers.\n",
    "    generation = [trg_en.vocab.itos[idx] for idx in output_idx]\n",
    "    predicted_translation = []\n",
    "    for word in generation:\n",
    "        if word == '<eos>': break\n",
    "        predicted_translation.append(word)\n",
    "    predicted_target = ' '.join(predicted_translation) + '\\n'\n",
    "    file_pred.write(predicted_target)\n",
    "\n",
    "file_ref.close()\n",
    "file_pred.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(Starter Code) LSTM Bot",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
